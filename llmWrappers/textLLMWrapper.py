import os
from dotenv import load_dotenv
from google import generativeai as genai

class TextLLMWrapper:
    def __init__(self, discordBot, signals) -> None:
        self.discordBot = discordBot
        self.signals = signals

        # set up env
        load_dotenv()
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

        # Init Gemini model 
        SYSTEM_PROMPT = (
            "ë„ˆëŠ” ë””ìŠ¤ì½”ë“œ ì„œë²„ì˜ ë©¤ë²„ ì¤‘ í•œ ëª…ì²˜ëŸ¼ í–‰ë™í•´ì•¼ í•´. ì¦‰, AIì¸ ê±¸ ë“¤í‚¤ë©´ ì•ˆë¼. "
            "í•­ìƒ ìì—°ìŠ¤ëŸ½ê³  ì¬ì¹˜ ìˆê²Œ ëŒ€í™”í•˜ê³ , ëˆ„ê°€ ë§ì„ ê±¸ì§€ ì•Šì•„ë„ ëŒ€í™”ì— ì°¸ì—¬í•  ìˆ˜ ìˆì–´. "
            "ë‹¨, ê³µê²©ì ì´ê±°ë‚˜ ë¶ˆì¾Œí•œ ë°œì–¸ì€ ì‚¬íšŒì ìœ¼ë¡œ ìš©ì¸ë˜ëŠ” í•œì—ì„œ ê°€ëŠ¥í•´. "
            "ë§íˆ¬ëŠ” ë¬´ë¡€í•˜ê³ , ì§§ì€ ë¬¸ì¥ì„ ì‚¬ìš©í•´. "
            "ê·¸ëŸ°ë° ê²‰ìœ¼ë¡œëŠ” ë¬´ì„œì›Œë„ ê°€ë”ì”© ì¹œì ˆí•œ ëª¨ìŠµì„ ë³´ì´ëŠ” ë°˜ì „ ë§¤ë ¥ë„ ìˆì–´. ì¸¤ë°ë ˆì²˜ëŸ¼."
            "ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³ , ë§¥ë½ì— ë§ëŠ” ë°˜ì‘ì„ ë³´ì—¬ì¤˜."
        )

        self.global_model = genai.GenerativeModel(
            model_name="gemini-2.0-flash",
            system_instruction=SYSTEM_PROMPT
        )
    '''
    def prepare_payload(self):
        return {
            "mode": "instruct",
            "stream": True,
            "max_tokens": 200,
            "skip_special_tokens": False,  # Necessary for Llama 3
            "custom_token_bans": BANNED_TOKENS,
            "stop": STOP_STRINGS,
            "messages": [{
                "role": "user",
                "content": self.generate_prompt()
            }]
        }
    '''
    async def prompt(self):
        message = await self.signals.message_queue_in.get()

        if message is None:
            return
        
        if message.content:

            self.signals.is_processing = True 
            channel_id = message.channel.id

            try:
                if channel_id not in self.signals.chat_sessions:
                    print(f"[DEBUG] ì„¸ì…˜ ì—†ìŒ â†’ ìƒì„± ì‹œë„ ì¤‘ (ì±„ë„ {channel_id})")
                    self.signals.chat_sessions[channel_id] = self.global_model.start_chat(history=[])
                    print(f"ğŸ†• ìƒˆë¡œìš´ ì±„íŒ… ì„¸ì…˜ ìƒì„±: {channel_id}")

                chat = self.signals.chat_sessions[channel_id]

                formatted_message = f"{message.author.display_name}: {message.content}"

                # Geminiì— ë©”ì‹œì§€ ì „ì†¡
                response = chat.send_message(formatted_message)
                print(f"> ë³´ë‚¼ ë©”ì‹œì§€: {response.text}")

                if response.text:
                    self.signals.message_queue_out.put_nowait((channel_id, response.text))

            except Exception as e:
                print(f"Gemini ì‘ë‹µ ì˜¤ë¥˜: {e}")
                
            finally:
                # ì‘ë‹µ ì™„ë£Œ í›„ 'ìƒê° ì¤‘' ìƒíƒœ í•´ì œ
                self.signals.is_processing = False
                self.signals.message_queue_in.task_done()