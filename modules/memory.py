from modules.module import Module
from constants import *
from chromadb.config import Settings
from google.genai import types
import chromadb
import requests
import json
import uuid
import asyncio
import copy


class Memory(Module):

    def __init__(self, signals, enabled=True):
        super().__init__(signals, enabled)

        self.API = self.API(self)
        self.prompt_injection.text = ""
        self.prompt_injection.priority = 60

        self.processed_count = 0

        self.chroma_client = chromadb.PersistentClient(path="./memories/chroma.db", settings=Settings(anonymized_telemetry=False))
        self.collection = self.chroma_client.get_or_create_collection(name="neurorong_collection")
        print(f"MEMORY: Loaded {self.collection.count()} memories from database.")
        if self.collection.count() == 0:
            print("MEMORY: No memories found in database. Importing from memoryinit.json")
            self.API.import_json(path="./memories/memoryinit.json")

    def get_prompt_injection(self):
        # Use recent messages and twitch messages to query the database for related memories
        query = ""

        for message in self.signals.recentDiscordMessages:
            query += message + "\n"

        for message in self.signals.history[-MEMORY_QUERY_MESSAGE_COUNT:]:
            if message["role"] == "user" and message["content"] != "":
                query += HOST_NAME + ": " + message["content"] + "\n"
            elif message["role"] == "assistant" and message["content"] != "":
                query += AI_NAME + ": " + message["content"] + "\n"

        memories = self.collection.query(query_texts=query, n_results=MEMORY_RECALL_COUNT)

        # Generate injection for LLM prompt
        self.prompt_injection.text = f"{AI_NAME} knows these things:\n"
        for i in range(len(memories["ids"][0])):
            self.prompt_injection.text += memories['documents'][0][i] + "\n"
        self.prompt_injection.text += "End of knowledge section\n"

        return self.prompt_injection

    async def run(self):
        # Periodically, check if at least 20 new messages have been sent, and if so, generate 3 question-answer pairs
        # to be stored into memory.
        # This is a technique called reflection. You essentially ask the AI what information is important in the recent
        # conversation, and it is converted into a memory so that it can be recalled later.
        while not self.signals.terminate:
            if self.processed_count > len(self.signals.history):
                self.processed_count = 0

            if len(self.signals.history) - self.processed_count >= 20:
                print("MEMORY: Generating new memories")

                # Copy the latest unprocessed messages
                messages = copy.deepcopy(self.signals.history[-(len(self.signals.history) - self.processed_count):])

                for message in messages:
                    if message["role"] == "user" and message["content"] != "":
                        message["content"] = HOST_NAME + ": " + message["content"] + "\n"
                    elif message["role"] == "assistant" and message["content"] != "":
                        message["content"] = AI_NAME + ": " + message["content"] + "\n"

                chat_section = ""
                for message in messages:
                    chat_section += message["content"]

                # ì‹¤ì œ ëŒ€í™” ë‚´ìš©ì„ ë‹¨ì¼ 'user' ë©”ì‹œì§€ë¡œ êµ¬ì„±
                conversation_history = [{
                    "role": "user",
                    # chat_section (ìµœê·¼ ëŒ€í™”)ë¥¼ ìš”ì²­ ë‚´ìš©ìœ¼ë¡œ ì „ë‹¬
                    "parts": [{"text": chat_section}] 
                }]

                # 3ê°œì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì„ ë‹´ì„ JSON ìŠ¤í‚¤ë§ˆ ì •ì˜
                memory_schema = types.Schema(
                    type=types.Type.OBJECT,
                    properties={
                        "memories": types.Schema(
                            type=types.Type.ARRAY,
                            items=types.Schema(
                                type=types.Type.OBJECT,
                                properties={
                                    "question": types.Schema(type=types.Type.STRING),
                                    "answer": types.Schema(type=types.Type.STRING),
                                },
                                required=["question", "answer"],
                            ),
                        )
                    },
                    required=["memories"]
                )

                try:
                    # 2. ë¹„ë™ê¸° í˜¸ì¶œ: requests.post ëŒ€ì‹  AsyncClient ì‚¬ìš©
                    response = await self.global_model.models.generate_content(
                        model='gemini-2.0-flash',  # ì ì ˆí•œ Gemini ëª¨ë¸ ì„ íƒ
                        contents=conversation_history,
                        config={
                            "system_instruction": MEMORY_PROMPT, # MEMORY_PROMPTëŠ” ì´ì œ ëª¨ë¸ ì—­í•  ì •ì˜ì— ì§‘ì¤‘
                            "max_output_tokens": 500, # JSON ì¶œë ¥ì— ë§ì¶° í† í° ì¦ê°€
                            "response_mime_type": "application/json", # ğŸš¨ JSON ì¶œë ¥ ê°•ì œ
                            "response_schema": memory_schema        # ğŸš¨ ìŠ¤í‚¤ë§ˆ ì •ì˜
                        }
                    )
                    
                    # 3. ì‘ë‹µì—ì„œ ë‚´ìš© ì¶”ì¶œ
                    raw_memories = response.text
                    print(f"MEMORY: Raw memories generated: {raw_memories[:50]}...")
                    
                    try:
                        # 1. JSON ë¬¸ìì—´ íŒŒì‹±
                        # response.textëŠ” JSON ëª¨ë“œ ì„¤ì • ë•ë¶„ì— ìœ íš¨í•œ JSON ë¬¸ìì—´ì¼ ê²ƒì…ë‹ˆë‹¤.
                        raw_memories_json_str = response.text
                        
                        # JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                        memory_data = json.loads(raw_memories_json_str)

                        # 2. ë©”ëª¨ë¦¬ ì¶”ì¶œ ë° ë°ì´í„°ë² ì´ìŠ¤ì— upsert
                        new_memories_to_upsert = []
                        
                        # JSON ìŠ¤í‚¤ë§ˆì˜ 'memories' ë°°ì—´ì„ ë°˜ë³µí•˜ë©° Q&A ìŒì„ ì¶”ì¶œ
                        for item in memory_data.get('memories', []):
                            question = item.get('question', '').strip()
                            answer = item.get('answer', '').strip()
                            
                            # Q&A ìŒì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•© (ì»¬ë ‰ì…˜ì— ì €ì¥ë  Document)
                            if question and answer:
                                # ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ëŠ” í¬ë§·ì„ ì‚¬ìš©í•˜ì—¬ ì €ì¥
                                full_memory = f"Q: {question}\nA: {answer}" 
                                new_memories_to_upsert.append(full_memory)

                        # 3. ë°ì´í„°ë² ì´ìŠ¤ì— ì¼ê´„ ì €ì¥ (Upsert)
                        if new_memories_to_upsert:
                            ids = [str(uuid.uuid4()) for _ in new_memories_to_upsert]
                            
                            # upsertëŠ” ë¹„ë™ê¸° ì‘ì—…ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ self.collectionì´ ë¹„ë™ê¸°ë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•¨
                            # ChromaDB Python í´ë¼ì´ì–¸íŠ¸ì˜ upsertëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ, ê·¸ëŒ€ë¡œ ì‚¬ìš©.
                            self.collection.upsert(
                                ids=ids,
                                documents=new_memories_to_upsert,
                                metadatas=[{"type": "short-term"}] * len(ids)
                            )
                            print(f"MEMORY: {len(new_memories_to_upsert)}ê°œì˜ ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

                        # 4. ì²˜ë¦¬ëœ ë©”ì‹œì§€ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
                        self.processed_count = len(self.signals.history) 

                    except json.JSONDecodeError as e:
                        print(f"MEMORY: JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ. ì›ë³¸ í…ìŠ¤íŠ¸: {raw_memories_json_str[:100]}...")
                    except Exception as e:
                        print(f"MEMORY: ë©”ëª¨ë¦¬ ì €ì¥ ì¤‘ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    
                    # ì²˜ë¦¬ëœ ë©”ì‹œì§€ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
                    self.processed_count = len(self.signals.history) 

                except Exception as e:
                    print(f"MEMORY: Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    await asyncio.sleep(5) # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì‹œ ëŒ€ê¸°

            await asyncio.sleep(5)

    class API:
        def __init__(self, outer):
            self.outer = outer

        def create_memory(self, data):
            id = str(uuid.uuid4())
            self.outer.collection.upsert(id, documents=data, metadatas={"type": "short-term"})

        def delete_memory(self, id):
            self.outer.collection.delete(id)

        def wipe(self):
            self.outer.chroma_client.reset()
            self.outer.chroma_client.create_collection(name="neuro_collection")

        def clear_short_term(self):
            short_term_memories = self.outer.collection.get(where={"type": "short-term"})
            for id in short_term_memories["ids"]:
                self.outer.collection.delete(id)

        def import_json(self, path="./memories/memories.json"):
            with open(path, "r") as file:
                try:
                    data = json.load(file)
                except json.JSONDecodeError:
                    print("Error decoding JSON file")
                    return

            for memory in data["memories"]:
                self.outer.collection.upsert(memory["id"], documents=memory["document"], metadatas=memory["metadata"])

        def export_json(self, path="./memories/memories.json"):
            memories = self.outer.collection.get()

            data = {"memories": []}
            for i in range(len(memories["ids"])):
                data["memories"].append({"id": memories["ids"][i],
                                         "document": memories["documents"][i],
                                        "metadata": memories["metadatas"][i]})

            with open(path, "w") as file:
                json.dump(data, file)

        def get_memories(self, query=""):
            data = []

            if query == "":
                memories = self.outer.collection.get()
                for i in range(len(memories["ids"])):
                    data.append({"id": memories["ids"][i],
                                 "document": memories["documents"][i],
                                 "metadata": memories["metadatas"][i]})
            else:
                memories = self.outer.collection.query(query_texts=query, n_results=30)
                for i in range(len(memories["ids"][0])):
                    data.append({"id": memories["ids"][0][i],
                                 "document": memories["documents"][0][i],
                                 "metadata": memories["metadatas"][0][i],
                                 "distance": memories["distances"][0][i]})

                # Sort memories by distance
                data = sorted(data, key=lambda x: x["distance"])
            return data