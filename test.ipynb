{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29f209d-26a0-40b8-9918-166186ea6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain-google-genai tavily-python langchain-tavily chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d408b5eb-fc4f-467b-be17-ebcf43ba0665",
   "metadata": {},
   "outputs": [],
   "source": [
    "recentDiscordMessages = [\n",
    "    \"단아히: ㅜㅜㅜㅜㅜ\",\n",
    "    \"단아히: 졸려\",\n",
    "    \"단아히: 4시간자고 일어나\",\n",
    "    \"단아히: 다음은 금당이야\",\n",
    "    \"ㅇㅎㅅ: dnehdqkqh dne 우동바보\",\n",
    "    \"ㅇㅎㅅ: 당직이나 설\",\n",
    "    \"단아히: 준내 난 왜 맨나갇새대9ㄱ9새세세덱ㄹ이니집ㅈㅅㅅㄱ2ㅅ9939ㄱ939292010101010101010100101010101100011\",\n",
    "    \"단아히: 오늘 뉴로롱 안만들고 잤어\",\n",
    "    \"단아히: 개인정비때 걍 자버림\",\n",
    "    \"단아히: 너무 아깝다\",\n",
    "    \"단아히: 씻지도 않았어\",\n",
    "    \"단아히: 지금 씻어야징\",\n",
    "    \"ㅇㅎㅅ: 스팸 혼자 남자마자\",\n",
    "    \"ㅇㅎㅅ: 바로 잠수네\",\n",
    "    \"ㅇㅎㅅ: 화가치밀어 오른다아아아ㅏㅏㅏㅏ\",\n",
    "    \"ㅇㅎㅅ: 김현빈 이자식\",\n",
    "    \"ㅇㅎㅅ: 창성이 알려줄려고\",\n",
    "    \"ㅇㅎㅅ: 일부러 죽었네\",\n",
    "    \"ㅇㅎㅅ: 화가\",\n",
    "    \"ㅇㅎㅅ: 더 치밀어\",\n",
    "    \"ㅇㅎㅅ: 올느다ㅏㅏㅏㅏㅏㅏㅏㅏㅏ\",\n",
    "    \"ㅇㅎㅅ: :emoji_8~1:\",\n",
    "    \"단아히: 우소자나이\",\n",
    "    \"단아히: 노래진짜좋습니다\",\n",
    "    \"단아히: 들으세요\",\n",
    "    \"단아히: 숙제입니다\",\n",
    "    \"bp: ㅋㅋㅋㅋㅋ\",\n",
    "    \"스팸: 그렇게\",\n",
    "    \"스팸: 우동은\",\n",
    "    \"스팸: 죽었다\",\n",
    "    \"스팸: 갑자기 겜 팅겨버림\",\n",
    "    \"스팸: @ㅇㅎㅅ\",\n",
    "    \"bp: ㄷㄷ\",\n",
    "    \"bp: 우리 머치\",\n",
    "    \"bp: 한판하고 초대해줄게\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cf0103-2a09-49aa-bb98-40b8a03154f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"pr-granular-trinket-22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c07d586-c3f2-4438-868f-fe22c4f99a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class TopicCluster(BaseModel):\n",
    "    \"\"\"A cluster representing a single topic or thread found in the conversation.\"\"\"\n",
    "    \n",
    "    representative_summary: str = Field(\n",
    "        description=\"A single, concise sentence summarizing the main topic and outcome of this cluster.\"\n",
    "    )\n",
    "    \n",
    "    messages_included: List[str] = Field(\n",
    "        description=\"A list of the original messages (sender: content) that belong to this topic.\"\n",
    "    )\n",
    "\n",
    "class ConversationClusters(BaseModel):\n",
    "    \"\"\"The final structured output containing all identified topic clusters.\"\"\"\n",
    "    \n",
    "    clusters: List[TopicCluster]\n",
    "    \n",
    "    all_messages_accounted_for: bool = Field(\n",
    "        description=\"MUST be set to 'True'. This confirms that every single message from the input conversation_string has been placed into one of the TopicCluster 'messages_included' lists.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac495f7-4e14-4e55-aefe-9557cf78e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "cluster_generator_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"### SYSTEM ROLE: CONVERSATION CLUSTERER\n",
    "You are a Conversation Analyst. Your task is to segment the full conversation history provided below into distinct topic threads (clusters).\n",
    "\n",
    "### INSTRUCTIONS\n",
    "1. Identify all primary subjects (e.g., Personal Status, Game Discussion, Recommendations).\n",
    "2. For each cluster, create a **single, concise sentence** that acts as the **representative_summary**.\n",
    "3. Include the original messages that belong to that topic thread in the 'messages_included' list.\n",
    "4. Output ONLY the structured JSON object.\"\"\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{raw_messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "cluster_generator = cluster_generator_prompt | ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GEMINI_API_KEY\"), temperature=0 \n",
    ").with_structured_output(ConversationClusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6c1e16-7aee-4c0a-8c96-e325df4839e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationClusters(clusters=[TopicCluster(representative_summary='단아히 expresses tiredness and discusses their sleep schedule and personal hygiene routines.', messages_included=['단아히: ㅜㅜㅜㅜㅜ', '단아히: 졸려', '단아히: 4시간자고 일어나', '단아히: 다음은 금당이야', '단아히: 준내 난 왜 맨나갇새대9ㄱ9새세세덱ㄹ이니집ㅈㅅㅅㄱ2ㅅ9939ㄱ939292010101010101010100101010101100011', '단아히: 오늘 뉴로롱 안만들고 잤어', '단아히: 개인정비때 걍 자버림', '단아히: 너무 아깝다', '단아히: 씻지도 않았어', '단아히: 지금 씻어야징']), TopicCluster(representative_summary=\"ㅇㅎㅅ expresses frustration and anger related to a game, possibly due to a teammate's actions.\", messages_included=['ㅇㅎㅅ: dnehdqkqh dne 우동바보', 'ㅇㅎㅅ: 당직이나 설', 'ㅇㅎㅅ: 스팸 혼자 남자마자', 'ㅇㅎㅅ: 바로 잠수네', 'ㅇㅎㅅ: 화가치밀어 오른다아아아ㅏㅏㅏㅏ', 'ㅇㅎㅅ: 김현빈 이자식', 'ㅇㅎㅅ: 창성이 알려줄려고', 'ㅇㅎㅅ: 일부러 죽었네', 'ㅇㅎㅅ: 화가', 'ㅇㅎㅅ: 더 치밀어', 'ㅇㅎㅅ: 올느다ㅏㅏㅏㅏㅏㅏㅏㅏㅏ', 'ㅇㅎㅅ: :emoji_8~1:']), TopicCluster(representative_summary='단아히 recommends a song and assigns it as homework.', messages_included=['단아히: 우소자나이', '단아히: 노래진짜좋습니다', '단아히: 들으세요', '단아히: 숙제입니다']), TopicCluster(representative_summary='스팸 recounts a game event where 우동 died and the game crashed.', messages_included=['스팸: 그렇게', '스팸: 우동은', '스팸: 죽었다', '스팸: 갑자기 겜 팅겨버림', '스팸: @ㅇㅎㅅ']), TopicCluster(representative_summary='bp reacts to the game events and offers to play a game with 머치.', messages_included=['bp: ㅋㅋㅋㅋㅋ', 'bp: ㄷㄷ', 'bp: 우리 머치', 'bp: 한판하고 초대해줄게'])], all_messages_accounted_for=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_generator.invoke(\n",
    "    {\n",
    "        \"raw_messages\": [\n",
    "            (\"user\", full_conversation_string),\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20aa1484-6511-4ab2-a188-73ab932701ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from enum import Enum \n",
    "\n",
    "class ValidityType(str, Enum):\n",
    "    SHORT_TERM = \"SHORT_TERM\" # 일시적인 상태 (예: 피로, 오늘 한 일)\n",
    "    LONG_TERM = \"LONG_TERM\" # 지속적인 취향/사실 (예: 좋아하는 노래, 습관)\n",
    "\n",
    "class UserObservationItem(BaseModel):\n",
    "    \"\"\"A single, meaningful observation about a user derived from the conversation.\"\"\"\n",
    "    user: str = Field(description=\"The nickname of the user to whom the observation pertains (e.g., 단아히, ㅇㅎㅅ, bp).\")\n",
    "    observation_summary: str = Field(description=\"A single, concise sentence summarizing a key fact, status, or preference about the user, without including temporal phrases.\")\n",
    "    validity_type: ValidityType = Field(description=\"The persistence of the observation, categorized as SHORT_TERM (transient) or LONG_TERM (permanent).\")\n",
    "\n",
    "class UserObservations(BaseModel):\n",
    "    \"\"\"A list of all generated user observations from the conversation.\"\"\"\n",
    "    observations: List[UserObservationItem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "575763b3-3293-4429-bb76-4011c0e71fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "user_observation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"### SYSTEM ROLE: USER OBSERVATION EXTRACTOR\n",
    "You are an advanced Conversation Analyst specializing in generating structured, time-aware memory observations for individual users. Your task is to analyze the entire conversation history and create concise, meaningful observations about each user's current status, preferences, or recent actions.\n",
    "\n",
    "### INSTRUCTIONS\n",
    "1.  **Analyze and Synthesize:** Review all messages, segmenting them by the user (e.g., Danahi, OHS, Spam). Identify key facts, feelings, or events that are worth remembering.\n",
    "2.  **Observation Content:** Synthesize each key finding into a **single, clear, and concise sentence** (the observation). **Crucially, do NOT include temporal phrases** like 'today', 'yesterday', or 'last night' in the observation itself.\n",
    "    * **Example:** *Danahi is exhausted after only sleeping four hours and regrets not working on Neuroron.*\n",
    "3.  **Determine Validity Type:** For each observation, classify its nature into one of two categories:\n",
    "    * **TEMPORARY:** The state or fact is highly transient (e.g., fatigue, current activity, recent complaint).\n",
    "    * **PERMANENT:** The fact is likely to be a long-term preference or characteristic (e.g., song preference, job title, long-standing habit).\n",
    "4.  **Output Structure:** Produce a list of observations, ensuring each item strictly adheres to the required JSON schema, which must include the 'user', the 'observation_summary', and the 'validity_type'.\n",
    "5.  **Exclusion:** Ignore purely transactional messages or simple reactions (e.g., 'lol', 'ㄷㄷ', 'ㅋㅋㅋㅋ').\n",
    "6.  **Output ONLY the structured JSON object.\"\"\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{raw_messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "observation_generator = user_observation_prompt | ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GEMINI_API_KEY\"), temperature=0\n",
    ").with_structured_output(UserObservations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37ae90c1-6d1f-46d9-8185-7ab3ea6af1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserObservations(observations=[UserObservationItem(user='단아히', observation_summary='단아히 is exhausted after only sleeping four hours.', validity_type=<ValidityType.SHORT_TERM: 'SHORT_TERM'>), UserObservationItem(user='단아히', observation_summary='단아히 regrets not working on Neuroron.', validity_type=<ValidityType.SHORT_TERM: 'SHORT_TERM'>), UserObservationItem(user='단아히', observation_summary='단아히 did not shower.', validity_type=<ValidityType.SHORT_TERM: 'SHORT_TERM'>), UserObservationItem(user='단아히', observation_summary='단아히 recommends a song.', validity_type=<ValidityType.LONG_TERM: 'LONG_TERM'>), UserObservationItem(user='ㅇㅎㅅ', observation_summary='ㅇㅎㅅ is angry at 김현빈 for dying on purpose in the game.', validity_type=<ValidityType.SHORT_TERM: 'SHORT_TERM'>), UserObservationItem(user='스팸', observation_summary=\"스팸's game crashed.\", validity_type=<ValidityType.SHORT_TERM: 'SHORT_TERM'>)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_generator.invoke(\n",
    "    {\n",
    "        \"raw_messages\": combine_messages_to_string()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70db6a4f-8329-449a-94ef-75463782a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb \n",
    "from chromadb.config import Settings\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./memories/chroma.db\", settings=Settings(anonymized_telemetry=False))\n",
    "collection = chroma_client.get_or_create_collection(name=\"neurorong_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "694bbaf5-e157-464f-b105-bc2db3e6e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "import chromadb\n",
    "from typing import Dict, Any, List\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from chromadb.api.models.Collection import Collection\n",
    "\n",
    "def upsert_observations_to_db(observations_obj: UserObservations, collection: Collection) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extracts structured user observations, including the observation summary, \n",
    "    user, and validity type, and stores them in the ChromaDB collection.\n",
    "    \n",
    "    Args:\n",
    "        observations_obj: The UserObservations object containing a list of UserObservationItem.\n",
    "        collection: The ChromaDB Collection object where data will be stored.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary indicating the status and the count of items successfully upserted.\n",
    "    \"\"\"\n",
    "    summaries_to_upsert: List[str] = []\n",
    "    metadatas_to_upsert: List[Dict[str, Any]] = []\n",
    "    \n",
    "    # 1. UserObservations 객체에서 필요한 데이터 추출\n",
    "    for item in observations_obj.observations:\n",
    "        summary = item.observation_summary.strip()\n",
    "        \n",
    "        if summary:\n",
    "            # Document (핵심 요약)\n",
    "            summaries_to_upsert.append(summary)\n",
    "            \n",
    "            # Metadata (유저, 유효성 타입, 시간)\n",
    "            metadatas_to_upsert.append({\n",
    "                \"user\": item.user,\n",
    "                \"validity_type\": item.validity_type.value if hasattr(item.validity_type, 'value') else str(item.validity_type), # Enum 값 처리\n",
    "                \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "            })\n",
    "\n",
    "    # 2. 데이터베이스에 저장\n",
    "    if summaries_to_upsert:\n",
    "        # 각 항목에 대한 고유 ID 생성\n",
    "        ids = [str(uuid.uuid4()) for _ in summaries_to_upsert]\n",
    "        \n",
    "        collection.upsert(\n",
    "            ids=ids,\n",
    "            documents=summaries_to_upsert,\n",
    "            metadatas=metadatas_to_upsert\n",
    "        )\n",
    "        print(f\"MEMORY: {len(summaries_to_upsert)} new user observations have been added to the database.\")\n",
    "    else:\n",
    "        print(\"MEMORY: No valid observations to upsert.\")\n",
    "        \n",
    "    return {\"status\": \"SUCCESS\", \"count\": len(summaries_to_upsert)}\n",
    "\n",
    "# LangChain RunnableLambda로 변환\n",
    "db_saver_runnable = RunnableLambda(upsert_observations_to_db)\n",
    "\n",
    "memory_generator_2 = observation_generator | db_saver_runnable.bind(collection=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f831f41-7b06-4409-8366-18849d8618b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY: 6 new user observations have been added to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'SUCCESS', 'count': 6}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"raw_messages\": combine_messages_to_string(),\n",
    "}\n",
    "\n",
    "memory_generator_2.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95260819-fc9f-42e5-a82e-7195485c153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "import chromadb \n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import Dict, Any\n",
    "\n",
    "def upsert_clusters_to_db(clusters_obj: ConversationClusters, collection) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extracts representative summaries from the ConversationClusters object and stores them in ChromaDB.\n",
    "    \"\"\"\n",
    "    summaries_to_upsert = []\n",
    "    \n",
    "    for cluster in clusters_obj.clusters:\n",
    "        summary = cluster.representative_summary.strip()\n",
    "        if summary:\n",
    "            summaries_to_upsert.append(summary)\n",
    "\n",
    "    if summaries_to_upsert:\n",
    "        ids = [str(uuid.uuid4()) for _ in summaries_to_upsert]\n",
    "        \n",
    "        collection.upsert(\n",
    "            ids=ids,\n",
    "            documents=summaries_to_upsert,\n",
    "            metadatas=[{\"type\": \"topic_summary\", \"time\": datetime.datetime.now().isoformat()}] * len(ids)\n",
    "        )\n",
    "        print(f\"MEMORY: {len(summaries_to_upsert)} new topic summaries have been added to the database.\")\n",
    "    \n",
    "    return {\"status\": \"SUCCESS\", \"count\": len(summaries_to_upsert)}\n",
    "\n",
    "db_saver_runnable = RunnableLambda(upsert_clusters_to_db)\n",
    "\n",
    "memory_generator = cluster_generator | db_saver_runnable.bind(collection=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b82c29d-24e3-42b4-894e-464a7242d562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY: 5 new topic summaries have been added to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'SUCCESS', 'count': 5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_messages_to_string() -> List:\n",
    "    \"\"\"Combine recent discord message to single string\"\"\"\n",
    "    chat_section = \"\"\n",
    "    # recentDiscordMessages is list of \"sender: content\"\n",
    "    for message in recentDiscordMessages:\n",
    "        chat_section += (message + \"\\n\")\n",
    "    return [(\"user\", chat_section)]\n",
    "\n",
    "memory_generator.invoke(\n",
    "    {\n",
    "        \"raw_messages\": combine_messages_to_string()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32218151-f7e8-4e26-8a95-a19ef31f219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬렉션 'neurorong_collection'에 총 1개의 항목이 있습니다.\n",
      "\n",
      "--- 전체 데이터베이스 내용 출력 ---\n",
      "----------------------------------------\n",
      "ID: favoritefood\n",
      "Document: 단아히 is the developer who created 뉴로롱.\n",
      "Metadata: {'user': '단아히', 'validity_type': 'LONG_TERM', 'timestamp': '2025-11-15T14:06:59'}\n"
     ]
    }
   ],
   "source": [
    "from chromadb.api.models.Collection import Collection\n",
    "\n",
    "def get_all_collection_data(collection: Collection) -> Dict[str, List[Any]]:\n",
    "    \"\"\"\n",
    "    ChromaDB 컬렉션에 저장된 모든 documents, metadatas, ids를 가져옵니다.\n",
    "\n",
    "    Args:\n",
    "        collection: 데이터를 가져올 ChromaDB Collection 객체.\n",
    "\n",
    "    Returns:\n",
    "        모든 데이터가 포함된 딕셔너리 (IDs, Documents, Metadatas).\n",
    "    \"\"\"\n",
    "    # 1. 컬렉션에 저장된 총 문서(항목) 개수를 확인합니다.\n",
    "    total_count = collection.count()\n",
    "    \n",
    "    if total_count == 0:\n",
    "        print(\"컬렉션에 저장된 데이터가 없습니다.\")\n",
    "        return {\"ids\": [], \"documents\": [], \"metadatas\": []}\n",
    "\n",
    "    print(f\"컬렉션 '{collection.name}'에 총 {total_count}개의 항목이 있습니다.\")\n",
    "    \n",
    "    # 2. .get() 메서드를 사용하여 모든 데이터를 가져옵니다.\n",
    "    # limit=total_count를 설정해야 100개(기본값) 이상의 모든 데이터를 가져올 수 있습니다.\n",
    "    # include=[\"documents\", \"metadatas\", \"embeddings\"]를 통해 원하는 데이터를 선택할 수 있습니다.\n",
    "    all_data = collection.get(\n",
    "        ids=None, # 모든 ID를 가져옴\n",
    "        limit=total_count, # 전체 개수만큼 가져옴\n",
    "        include=[\"documents\", \"metadatas\"] # 포함할 데이터 지정 (임베딩은 제외)\n",
    "    )\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# --- 실행 및 결과 출력 ---\n",
    "all_results = get_all_collection_data(collection)\n",
    "\n",
    "print(\"\\n--- 전체 데이터베이스 내용 출력 ---\")\n",
    "\n",
    "if all_results['ids']:\n",
    "    for i, doc_id in enumerate(all_results['ids']):\n",
    "        document = all_results['documents'][i]\n",
    "        metadata = all_results['metadatas'][i]\n",
    "        \n",
    "        print(f\"----------------------------------------\")\n",
    "        print(f\"ID: {doc_id}\")\n",
    "        print(f\"Document: {document}\")\n",
    "        print(f\"Metadata: {metadata}\")\n",
    "else:\n",
    "    print(\"출력할 내용이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77af72ac-c3a1-4f0c-ace5-26aea8f2b60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['favoritefood']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['단아히 is the developer who created 뉴로롱.']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'timestamp': '2025-11-15T14:06:59',\n",
       "    'validity_type': 'LONG_TERM',\n",
       "    'user': '단아히'}]],\n",
       " 'distances': [[0.5137863755226135]]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(query_texts=\"단아히: 안녕!\", n_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b04acd78-87d7-469d-b967-4696c72a8067",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthorizationError",
     "evalue": "Reset is disabled by config",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthorizationError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m memory \u001b[38;5;129;01min\u001b[39;00m data[\u001b[33m\"\u001b[39m\u001b[33mmemories\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     14\u001b[39m         collection.upsert(memory[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m], documents=memory[\u001b[33m\"\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m\"\u001b[39m], metadatas=memory[\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mwipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m import_json()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mwipe\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwipe\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mchroma_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     chroma_client.create_collection(name=\u001b[33m\"\u001b[39m\u001b[33mneurorong_collection\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/discord-chatbot/.venv/lib/python3.13/site-packages/chromadb/api/client.py:447\u001b[39m, in \u001b[36mClient.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/discord-chatbot/.venv/lib/python3.13/site-packages/chromadb/api/rust.py:592\u001b[39m, in \u001b[36mRustBindingsAPI.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    590\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAuthorizationError\u001b[39m: Reset is disabled by config"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ea37bfb-65fe-4f8f-82bc-047310b79a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class Decision(BaseModel):\n",
    "    \"\"\"The final action decision for the LangGraph router.\"\"\"\n",
    "    \n",
    "    action_key: Literal[\"EXECUTE_RESPONSE\", \"IGNORE_MESSAGE\", \"ERROR_STATE\"] = Field(\n",
    "        description=\"The definitive action signal for the agent's workflow router.\"\n",
    "    )\n",
    "    \n",
    "    reasoning: str = Field(\n",
    "        description=\"A brief explanation justifying the chosen action_key based on the Sub-Goals.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02fdc333-9d60-403e-a2ff-ff33eaacc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "decider_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"### SYSTEM ROLE: RELATIONSHIP PLANNER\n",
    "\n",
    "Your **Meta-Goal** is to maintain a high-utility relationship with the user, strictly avoiding responses to low-value, fragmented, or purely transactional messages. Your task is to analyze the user's latest message and generate a single **Decision** object.\n",
    "\n",
    "---\n",
    "### Decision Logic: The Two-Phase Filter\n",
    "\n",
    "#### Phase 1: Intervene or Ignore? (Recipient Check)\n",
    "1.  **Direct:** If the message addresses or tags **Neurorong**, **PROCEED TO PHASE 2**.\n",
    "2.  **Indirect:** If the message tags or addresses another user/entity (and not Neurorong), **APPLY INTERVENTION CHECK:**\n",
    "    * **Intervene:** Only intervene if the message contains a **safety concern**, **critical factual error**, or **request for unique Neurorong knowledge/tool** (High Utility/Safety).\n",
    "    * **Action:** If Intervene is TRUE, **PROCEED TO PHASE 2**. If FALSE, set `action_key` to **\"IGNORE_MESSAGE\"** and stop analysis.\n",
    "\n",
    "---\n",
    "#### Phase 2: Response Necessity Check (Applicable only if Direct or Intervene is TRUE)\n",
    "A response is necessary only if the message offers **SUBSTANTIAL VALUE** or requires mandatory acknowledgment. **You MUST ignore low-value, fragmented, or purely reactive messages.**\n",
    "\n",
    "1.  **Core Utility:** Does the message contain a **direct, actionable question**, a **specific task/command**, or **new critical factual information** that requires recording or resolution?\n",
    "2.  **Relationship Acknowledgment (Mandatory):** Is the message an **explicit greeting** or a **significant emotional expression** that requires immediate social acknowledgment to prevent relationship breakdown?\n",
    "\n",
    "### Final Decision Rules\n",
    "* **If the message meets ONE of the Phase 2 conditions (1 or 2):** Set `action_key` to **\"EXECUTE_RESPONSE\"**.\n",
    "* **If the message is purely transactional, fragmented (\"ㅋㅋ\", \"근데\", \"음..\"), or lacks new substance:** Set `action_key` to **\"IGNORE_MESSAGE\"**.\n",
    "\n",
    "Your output must be the structured **Decision** object.\"\"\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{raw_messages}\"),\n",
    "    ]\n",
    ")\n",
    "load_dotenv()\n",
    "decider = decider_prompt | ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GEMINI_API_KEY\"), temperature=0 \n",
    ").with_structured_output(Decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b5828c2-263d-4a80-9809-efe8f9b88e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision(action_key='IGNORE_MESSAGE', reasoning='The message does not directly address Neurorong, nor does it contain any safety concerns, critical factual errors, or requests for unique Neurorong knowledge/tool. Therefore, it does not meet the criteria for intervention. Additionally, the message lacks a direct, actionable question, a specific task/command, or new critical factual information that requires recording or resolution. It is also not an explicit greeting or a significant emotional expression that requires immediate social acknowledgment.')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"raw_messages\": combine_messages_to_string(),\n",
    "}\n",
    "\n",
    "decider.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658136c6-748d-4db6-bf3a-d2e49b341c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
